\documentclass[10pt, spanish]{article}

\usepackage[none]{hyphenat}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish,es-nodecimaldot]{babel}
\usepackage{csquotes}
\usepackage{multicol}
\usepackage{pgf}

\usepackage{geometry}
\def\margin{18mm}
\geometry{
    a4paper,
    left=\margin,
    right=\margin,
    top=\margin,
    bottom=\margin
}

% \usepackage[sorting=none]{biblatex}
\usepackage{hyperref}

\usepackage{lmodern}
\usepackage{enumitem}
%\setenumerate{label=(\alph*),leftmargin=0.6cm}
% \setitemize{label=---,leftmargin=0.6cm}
\usepackage{amssymb}
\usepackage{mathtools}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

\usepackage{titlesec}

\titlespacing*{\section}{0pt}{.7em}{.5em}

% For diagrams
\usepackage{tikz}
\usetikzlibrary{arrows}

% Theorems
\usepackage{amsthm}
\usepackage{thmtools}
\newtheorem*{lema}{Lema}
\newtheorem*{obs}{Observación}
\newtheorem*{nota}{Nota}

\addto\captionsspanish{\renewcommand\proofname{Solución}}

\theoremstyle{definition}
\newtheorem*{defin}{Definición}
\newtheorem*{prop}{Proposición}
\newtheoremstyle{break}{}{}{}{}{\bfseries}{.}{.5em}{Ejercicio #2}
\theoremstyle{break}
\newtheorem{ej}{Ejercicio}

% No indentation
\setlength\parindent{0pt}
\setlength{\parskip}{0.5em}
\let\emptyset\varnothing

% Custom math commands
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}

\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}

\DeclareMathSymbol{*}{\mathbin}{symbols}{"01}

\DeclareMathOperator{\im}{Im}
%\DeclareMathOperator{\ker}{Ker}
\DeclareMathOperator{\mcm}{mcm}
\DeclareMathOperator{\mcd}{mcd}

\DeclareMathOperator{\bijmap}{\ \rlap{\ensuremath{\rightarrowtail}}%
    {\ensuremath{\mkern2mu\twoheadrightarrow}}}

\newcommand{\Zp}{\mathbb{Z}_{(p)}}

\usepackage{graphicx}
\graphicspath{ {./plots/} }


\usepackage{color}
\definecolor{gray75}{gray}{0.75}
\definecolor{pycommentcol}{rgb}{0.3,0.3,0.3}     % gray
\definecolor{pystatecol}{rgb}{0,0,0.7}           % blue
\definecolor{pystringcol}{rgb}{0,0.6,0}          % green
\definecolor{pyinbuiltscol}{rgb}{0.55,0.15,0.55} % plum
\definecolor{pyspecialcol}{rgb}{0.8,0.45,0.12}   % orange
\definecolor{mygray}{gray}{0.3}
\newcommand*{\pyfontfamily}{\fontfamily{DejaVuSansMono-TLF}\selectfont}

\usepackage{listings}
\lstset{inputpath=./}
\usepackage{xcolor}


\usepackage{textgreek}
\newcommand\pythonstyle{\lstset{
        language=Python,
        literate=%esto es para que acepte acentos
        {á}{{\'a}}1
        {í}{{\'i}}1
        {é}{{\'e}}1
        {ý}{{\'y}}1
        {ú}{{\'u}}1
        {ó}{{\'o}}1
        {ě}{{\v{e}}}1
        {š}{{\v{s}}}1
        {č}{{\v{c}}}1
        {ř}{{\v{r}}}1
        {ž}{{\v{z}}}1
        {ď}{{\v{d}}}1
        {ť}{{\v{t}}}1
        {ñ}{{\~n}}1
        {ň}{{\v{n}}}1                
        {ů}{{\r{u}}}1
        {Á}{{\'A}}1
        {Í}{{\'I}}1
        {É}{{\'E}}1
        {Ý}{{\'Y}}1
        {Ú}{{\'U}}1
        {Ó}{{\'O}}1
        {Ě}{{\v{E}}}1
        {Š}{{\v{S}}}1
        {Č}{{\v{C}}}1
        {Ř}{{\v{R}}}1
        {Ž}{{\v{Z}}}1
        {Ď}{{\v{D}}}1
        {Ť}{{\v{T}}}1
        {Ň}{{\v{N}}}1                
        {ε}{{\textepsilon}}1                
        {±}{{$\pm$}}1                
        {Ů}{{\r{U}}}1,
        basicstyle=\pyfontfamily\scriptsize,
        commentstyle=\color{pycommentcol}\itshape,
        emph={self,cls,@classmethod,@property}, % Custom highlighting
        emphstyle=\color{pyspecialcol}\itshape, % Custom highlighting style
        morestring=[b]{"""},
        stringstyle=\color{pystringcol},
        keywordstyle=\color{pystatecol},        % statements
        % remove any inbuilt functions from keywords
        deletekeywords={print},
        % Switch to predefined class that contain many, but not all,
        % inbuilt functions and classes
        classoffset=1,
        % add any inbuilts, not statements
        morekeywords={print,None,TypeError},
        keywordstyle=\color{pyinbuiltscol},
        frame=leftline,
        numberstyle=\sffamily\tiny\color{mygray},
        stepnumber=1,
        numbers=left,
        numbersep=10pt,                      
        showstringspaces=false            
}}

\usepackage[labelformat=empty, labelfont={bf,it}, textfont=bf]{caption}%ponga solo el nombre en los codigos

\pythonstyle
\begin{document}
\selectfont{\Large\textbf{Geometría computacional: Práctica 3}\hfill Adrián Lattes  Grassi} \noindent\rule{17cm}{1pt}

\section{Introducción}

En esta práctica he utilizado los algoritmos de clasificación \textit{KMeans} y
\textit{DBSCAN} sobre un sistema $X$ de 1000 elementos con dos estados cada uno.
Para ello he utilizado las implementaciones de estos algoritmos de la librería
\texttt{scikit-learn}.

\section{Método}

El programa está dividido en funciones que aislan las distintas funcionalidades
del mismo y permiten la reutilización y variación de parámetros del código:
\begin{itemize}
\setlength\itemsep{0em}
    \item \texttt{kmeans\_silhouettes} y \texttt{dbscan\_silhouettes}: Dado un
        sistema y un conjunto de parámetros (\textit{n} para \textit{KMeans} y
        \textit{ε} para \textit{DBSCAN}) calcula las vecindades
        correspondientes, con sus valores medios de los coeficientes de
        Silhouette.
    \item \texttt{kmeans\_elegir\_n\_clusters} y \texttt{dbscan\_elegir\_ε}:
        Devuelve el índice del valor máximo de los coeficientes de Silhouette
        calculados anteriormente. Además también dibuja la gráfica de los
        distintos valores de los coeficientes de Silhouette al variar el
        parámetro del algoritmo, destacando el rojo el valor máximo.
    \item \texttt{dbscan\_cluster\_centroids}:
        Calcula los centroides de las vecindades calculadas con \textit{DBSCAN},
        útiles para pintar las etiquetas en las gráficas.
    \item \texttt{plot\_clusters} y \texttt{plot\_voronoi}:
        Gráfica de las vecindades y diagrama de \textit{Voronoi}.
    \item \texttt{apartado1} y \texttt{apartado2}:
        Gestión de los plots y llamadas a las funciones anteriores.
\end{itemize}

\section{Resultados}
\subsection{Clasificación con algoritmo KMeans y predicción de nuevos estados}

El número de vecindades con mayor coeficiente de Silhouette para el algoritmo
\textit{KMeans} de entre los valores $[2,15]$ es el 3, como se puede ver en la
figura de la izquierda. Además es interesante observar que no hay ningún otro
valor que proporcione un coeficiente de Silhouette cercano al correspondiente a
3 vecindades.  Por otro lado este es precisamente el valor esperado, ya que los
estados del sistema han sido generados entorno a tres centros.

En la gráfica de la derecha se pueden observar las vecindades y diagrama
correspondientes a este número óptimo de vecindades. Aquí también he dibujado en
rojo los elementos $a=(0,0)$ y $b=(0,-1)$ que queremos clasificar. Con esto he
podido comparar el resultado esperado visualmente con el obtenido con el método
\texttt{kmeans.predict}.
\begin{itemize}
\setlength\itemsep{0em}
    \item El punto $a$ está visiblemente en la vecindad 2, lo que coincide con
        el resultado de  \texttt{kmeans.predict} 
    \item El punto $b$ está visiblemente en la frontera entre las regiones de
voronoi correspondientes a las vecindades 0 y 1. En este caso el método
\texttt{kmeans.predict} nos dice que el elemento pertenece a la vecindad 0, lo
que se corresponde con lo esperado, pero quizás es una información un tanto
imprecisa, ya que solo con este dato no sabemos que el punto está muy cerca de
la vecindad 1.  \end{itemize}

\vspace{-1em}

\begin{center}
    \makebox[\textwidth][c]{\scalebox{0.65}{\input{plots/kmeans.pgf}}}
\end{center}

\subsection{Clasificación con algoritmo DBSCAN}

Al aplicar el algoritmo \textit{DBSCAN} he fijado el número mínimo de elementos
en $n_0=10$ y he considerado los coeficientes de Silhouette correspondientes a
los valores del umbral de distancia $\varepsilon\in(0.1, 0.4)$, tanto para la
métrica euclideana como para la de Manhattan.

En las gŕaficas de la izquierda se puede observar que ahora los valores del
umbral de distancia con coeficiente de Silhouette máximo no están tan
diferenciados como en el caso del algoritmo \textit{KMeans}. Es decir, se intuye
que existe un entorno del valor óptimo $\varepsilon$ en el que el coeficiente de
Silhouette tiene una variación acotada.

Además, para ambas métricas, los coeficientes de Silhouette máximos son
considerablemente menores que en el caso anterior. Esto se refleja también en
las gráficas de la derecha, en las que están dibujadas las vecindades. En este
caso se han distinguido solo dos vecindades, estando agrupadas las vecindades 0
y 2 del apartado anterior en una sola. Con esto se entiende que el coeficiente
medio de Silhouette sea menor, ya que la vecindad 0 ahora es más grande y sus 
puntos están "más separados entre sí".

\subsubsection{DBSCAN con métrica euclideana}
\begin{center}
    \vspace{-1em}
    \makebox[\textwidth][c]{\scalebox{0.65}{\input{plots/dbscan-euclidean.pgf}}}
\end{center}
\subsubsection{DBSCAN con métrica de Manhattan}
\vspace{-1em}
\begin{center}
    \makebox[\textwidth][c]{\scalebox{0.65}{\input{plots/dbscan-manhattan.pgf}}}
\end{center}

\section{Conclusión}

Mi conclusión es que el algoritmo \textit{KMeans} tiene una mayor capacidad para
distinguir vecindades de estados que están muy cercanas, pero que se acumulan
entorno a puntos concretos, mientras que \textit{DBSCAN} no consigue hacer estas
distinciones debido a que está considerando los valores de la bola de radio
igual al umbral de distancia.

Además no he notado grandes diferencias entre usar una métrica u otra en el
algoritmo \textit{DBSCAN}.

\section{Código}

El siguiente código con la implementación también está adjunto en la entrega
y disponible, junto con esta memoria, en un repositorio git en el siguiente
enlace:
\href{https://www.github.com/haztecaso/gcomp22}{github.com/haztecaso/gcomp22}.
\vspace{1em}

\lstinputlisting[linerange={8}, firstnumber=8]{practica3.py}

\end{document}
